{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20be282b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADED DATA FROM EXCEL\n",
      "======================================================================\n",
      "\n",
      "Issuers: ['NVR US Equity', 'EBAY US Equity', 'MSI US Equity']\n",
      "\n",
      "Payoff (No Default): [1096.89213894  993.07854348  885.79231146]\n",
      "Payoff (Default):    [-15914.54602848 -15914.76145403 -14668.07900684]\n",
      "\n",
      "[CRITICAL] PDs loaded from Excel:\n",
      "  NVR US Equity: 2.1410517647e-38\n",
      "  EBAY US Equity: 2.0575996750e-15\n",
      "  MSI US Equity: 2.0367921874e-37\n",
      "Sum of PDs: 2.0575996750e-15\n",
      "\n",
      "Correlation columns found: ['NVR Return.1', 'EBAY Return.1', 'MSI Return.1']\n",
      "Correlation matrix shape: (3, 3)\n",
      "Correlation matrix:\n",
      "[[1.         0.33756865 0.4482751 ]\n",
      " [0.33756865 1.         0.35468667]\n",
      " [0.4482751  0.35468667 1.        ]]\n",
      "\n",
      "--- BRUTE FORCE (STREAMING) ---\n",
      "method: brute_force_streaming\n",
      "VaR: 0.0\n",
      "ES: 0.0\n",
      "Expected_Loss: 0.0\n",
      "P(Loss>0): 0.0\n",
      "alpha: 0.99\n",
      "simulations: 50000000\n",
      "note: Rare-event regime: VaR=0, ES=EL/(1-alpha).\n",
      "[IS] sims=50,000,000  EL≈3.49033e-27  P(L>0)≈2.06432e-31\n",
      "[IS] sims=100,000,000  EL≈3.63149e-27  P(L>0)≈2.14781e-31\n",
      "[IS] sims=150,000,000  EL≈3.85854e-27  P(L>0)≈2.2821e-31\n",
      "[IS] sims=200,000,000  EL≈1.6202e-26  P(L>0)≈9.58251e-31\n",
      "[IS] sims=250,000,000  EL≈1.9025e-26  P(L>0)≈1.12522e-30\n",
      "[IS] sims=300,000,000  EL≈5.24396e-24  P(L>0)≈3.1015e-28\n",
      "[IS] sims=350,000,000  EL≈5.24432e-24  P(L>0)≈3.10171e-28\n",
      "[IS] sims=400,000,000  EL≈5.24455e-24  P(L>0)≈3.10185e-28\n",
      "[IS] sims=450,000,000  EL≈5.24152e-24  P(L>0)≈3.10005e-28\n",
      "[IS] sims=500,000,000  EL≈5.24149e-24  P(L>0)≈3.10004e-28\n",
      "[IS] sims=550,000,000  EL≈5.24151e-24  P(L>0)≈3.10005e-28\n",
      "[IS] sims=600,000,000  EL≈5.24491e-24  P(L>0)≈3.10206e-28\n",
      "[IS] sims=650,000,000  EL≈5.57422e-24  P(L>0)≈3.29683e-28\n",
      "[IS] sims=700,000,000  EL≈5.59143e-24  P(L>0)≈3.30701e-28\n",
      "[IS] sims=750,000,000  EL≈5.61209e-24  P(L>0)≈3.31923e-28\n",
      "[IS] sims=800,000,000  EL≈5.61231e-24  P(L>0)≈3.31936e-28\n",
      "[IS] sims=850,000,000  EL≈5.63127e-24  P(L>0)≈3.33057e-28\n",
      "[IS] sims=900,000,000  EL≈5.63143e-24  P(L>0)≈3.33066e-28\n",
      "[IS] sims=950,000,000  EL≈5.63159e-24  P(L>0)≈3.33076e-28\n",
      "[IS] sims=1,000,000,000  EL≈5.63207e-24  P(L>0)≈3.33104e-28\n",
      "[IS] sims=1,050,000,000  EL≈5.63213e-24  P(L>0)≈3.33108e-28\n",
      "[IS] sims=1,100,000,000  EL≈5.5919e-24  P(L>0)≈3.30728e-28\n",
      "[IS] sims=1,150,000,000  EL≈5.5919e-24  P(L>0)≈3.30728e-28\n",
      "[IS] sims=1,200,000,000  EL≈5.59209e-24  P(L>0)≈3.3074e-28\n",
      "[IS] sims=1,250,000,000  EL≈5.59204e-24  P(L>0)≈3.30736e-28\n",
      "[IS] sims=1,300,000,000  EL≈3.12526e-23  P(L>0)≈1.84841e-27\n",
      "[IS] sims=1,350,000,000  EL≈3.1302e-23  P(L>0)≈1.85133e-27\n",
      "[IS] sims=1,400,000,000  EL≈3.1302e-23  P(L>0)≈1.85133e-27\n",
      "[IS] sims=1,450,000,000  EL≈3.13004e-23  P(L>0)≈1.85124e-27\n",
      "[IS] sims=1,500,000,000  EL≈5.92258e-23  P(L>0)≈3.50286e-27\n",
      "[IS] sims=1,550,000,000  EL≈5.92259e-23  P(L>0)≈3.50286e-27\n",
      "[IS] sims=1,600,000,000  EL≈5.92259e-23  P(L>0)≈3.50286e-27\n",
      "[IS] sims=1,650,000,000  EL≈5.92272e-23  P(L>0)≈3.50294e-27\n",
      "[IS] sims=1,700,000,000  EL≈5.92268e-23  P(L>0)≈3.50292e-27\n",
      "[IS] sims=1,750,000,000  EL≈5.92871e-23  P(L>0)≈3.50649e-27\n",
      "[IS] sims=1,800,000,000  EL≈5.92874e-23  P(L>0)≈3.5065e-27\n",
      "[IS] sims=1,850,000,000  EL≈5.92873e-23  P(L>0)≈3.5065e-27\n",
      "[IS] sims=1,900,000,000  EL≈5.92865e-23  P(L>0)≈3.50645e-27\n",
      "[IS] sims=1,950,000,000  EL≈5.92819e-23  P(L>0)≈3.50618e-27\n",
      "[IS] sims=2,000,000,000  EL≈5.92785e-23  P(L>0)≈3.50597e-27\n",
      "\n",
      "--- IMPORTANCE SAMPLING (STREAMING) ---\n",
      "method: importance_sampling_streaming\n",
      "VaR: 0.0\n",
      "ES: 5.927845091404082e-21\n",
      "Expected_Loss: 5.927845091404087e-23\n",
      "P(Loss>0): 3.50597423809602e-27\n",
      "alpha: 0.99\n",
      "simulations: 2000000000\n",
      "tilt_strength: 0.8\n",
      "tilted_default_paths_seen: 131017037\n",
      "note: Rare-event regime: VaR=0, ES=EL/(1-alpha).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "###############################################################################\n",
    "# CONFIG (UPDATED)\n",
    "###############################################################################\n",
    "EXCEL_PATH = r\"C:\\Users\\Tom\\Git Repos\\tomd6464\\Risk_1\\MCS_Bond_Sim\\MCS_Bond.xlsx\"\n",
    "\n",
    "ALPHA     = 0.99\n",
    "SEED      = 1\n",
    "PD_FLOOR  = 1e-50\n",
    "TILT      = 0.8\n",
    "\n",
    "# \"Lots of simulations\" but feasible:\n",
    "MIN_SIMS_BRUTE = 50_000_000        # guaranteed minimum sims (50m)\n",
    "MAX_SIMS_BRUTE = 2_000_000_000       # hard cap (2b)\n",
    "\n",
    "MIN_SIMS_IS    = 50_000_000        # guaranteed minimum sims (50m)\n",
    "MAX_SIMS_IS    = 2_000_000_000     # hard cap (2b)\n",
    "\n",
    "CHUNK = 5_000_000                  # fewer Python loop iterations\n",
    "\n",
    "# Early stopping based on relative standard error of Expected Loss estimate\n",
    "# (lower = more accurate, higher = faster)\n",
    "TARGET_REL_SE_BRUTE = 0.01         # 1% relative SE target for EL\n",
    "TARGET_REL_SE_IS    = 0.01         # 1% relative SE target for EL (under true measure)\n",
    "\n",
    "PRINT_EVERY_CHUNKS  = 10\n",
    "\n",
    "###############################################################################\n",
    "# LOAD DATA FROM EXCEL\n",
    "###############################################################################\n",
    "def load_bond_data(excel_path):\n",
    "    raw = pd.read_excel(excel_path, sheet_name=\"Bond_Data\", header=None)\n",
    "\n",
    "    issuer_row = raw.index[raw[1].astype(str).str.strip() == \"Issuer\"][0]\n",
    "    names = raw.loc[issuer_row, 2:4].tolist()\n",
    "\n",
    "    def get_row(label):\n",
    "        r = raw.index[raw[1].astype(str).str.strip() == label][0]\n",
    "        return raw.loc[r, 2:4].astype(float).to_numpy()\n",
    "\n",
    "    payoff_nd = get_row(\"Payoff N.d.\")\n",
    "    payoff_d  = get_row(\"Payoff (D)\")\n",
    "\n",
    "    kmv_row = raw.index[raw[1].astype(str).str.strip() == \"KMV Output\"][0]\n",
    "    pd_1y = raw.loc[kmv_row + 1, 2:4].astype(float).to_numpy()\n",
    "\n",
    "    return names, payoff_nd, payoff_d, pd_1y\n",
    "\n",
    "\n",
    "def load_corr(excel_path):\n",
    "    df = pd.read_excel(excel_path, sheet_name=\"Bond_Stock_data\", header=1)\n",
    "    norm_cols = [c for c in df.columns if str(c).endswith(\"Return.1\")]\n",
    "\n",
    "    if len(norm_cols) < 3:\n",
    "        raise ValueError(f\"Couldn't find 3 normalised return columns. Found: {norm_cols}\")\n",
    "\n",
    "    corr = df[norm_cols].dropna().corr().to_numpy()\n",
    "    corr = (corr + corr.T) / 2.0\n",
    "    np.fill_diagonal(corr, 1.0)\n",
    "    return corr, norm_cols\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# BRUTE FORCE (STREAMING) — NO HUGE LOSS ARRAY\n",
    "###############################################################################\n",
    "def mc_bruteforce_streaming(\n",
    "    payoff_nd, payoff_d, pd_1y, corr,\n",
    "    alpha, seed, pd_floor,\n",
    "    min_sims, max_sims, chunk,\n",
    "    target_rel_se, print_every_chunks=10\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    payoff_nd = np.asarray(payoff_nd, dtype=np.float32)\n",
    "    payoff_d  = np.asarray(payoff_d,  dtype=np.float32)\n",
    "    pd_1y     = np.asarray(pd_1y,     dtype=np.float32)\n",
    "    corr      = np.asarray(corr,      dtype=np.float32)\n",
    "\n",
    "    n = len(payoff_nd)\n",
    "    base = float(payoff_nd.sum())\n",
    "\n",
    "    L = np.linalg.cholesky(corr).astype(np.float32)\n",
    "    zcrit = norm.ppf(np.clip(pd_1y, pd_floor, 1 - 1e-12)).astype(np.float32)\n",
    "\n",
    "    # Streaming accumulators for EL and P(L>0)\n",
    "    sims_done = 0\n",
    "    sum_L = 0.0\n",
    "    sum_L2 = 0.0\n",
    "    count_pos = 0\n",
    "\n",
    "    chunks_done = 0\n",
    "    while sims_done < max_sims:\n",
    "        m = min(chunk, max_sims - sims_done)\n",
    "\n",
    "        z  = rng.standard_normal(size=(m, n)).astype(np.float32)\n",
    "        zc = z @ L.T\n",
    "\n",
    "        default = (zc < zcrit)\n",
    "        payoff = np.where(default, payoff_d, payoff_nd)  # vectorized\n",
    "        port_payoff = payoff.sum(axis=1, dtype=np.float32)\n",
    "        loss = (base - port_payoff).astype(np.float32)\n",
    "\n",
    "        # update streaming stats\n",
    "        sims_done += m\n",
    "        chunks_done += 1\n",
    "\n",
    "        loss64 = loss.astype(np.float64)  # for stable accumulation\n",
    "        sum_L  += float(loss64.sum())\n",
    "        sum_L2 += float((loss64 * loss64).sum())\n",
    "        count_pos += int((loss > 0).sum())\n",
    "\n",
    "        # early stop based on relative SE of mean(loss)\n",
    "        if sims_done >= min_sims:\n",
    "            mean = sum_L / sims_done\n",
    "            # sample variance of loss\n",
    "            var = max(0.0, (sum_L2 - sims_done * mean * mean) / max(1, sims_done - 1))\n",
    "            se = (var / sims_done) ** 0.5\n",
    "            rel_se = se / (abs(mean) + 1e-30)\n",
    "\n",
    "            if rel_se <= target_rel_se:\n",
    "                break\n",
    "\n",
    "        if print_every_chunks and (chunks_done % print_every_chunks == 0):\n",
    "            mean = sum_L / sims_done\n",
    "            ppos = count_pos / sims_done\n",
    "            print(f\"[BRUTE] sims={sims_done:,}  EL≈{mean:.6g}  P(L>0)≈{ppos:.6g}\")\n",
    "\n",
    "    EL = sum_L / sims_done\n",
    "    p_pos = count_pos / sims_done\n",
    "    p_tail = 1.0 - alpha\n",
    "\n",
    "    # In your rare-event setup, VaR often 0; we can at least return this correctly:\n",
    "    if p_pos < p_tail:\n",
    "        VaR = 0.0\n",
    "        ES = EL / p_tail if p_tail > 0 else 0.0\n",
    "        note = \"Rare-event regime: VaR=0, ES=EL/(1-alpha).\"\n",
    "    else:\n",
    "        VaR = None\n",
    "        ES = None\n",
    "        note = \"P(L>0) >= 1-alpha; need quantile method if you truly need VaR/ES.\"\n",
    "\n",
    "    return {\n",
    "        \"method\": \"brute_force_streaming\",\n",
    "        \"VaR\": VaR,\n",
    "        \"ES\": ES,\n",
    "        \"Expected_Loss\": EL,\n",
    "        \"P(Loss>0)\": p_pos,\n",
    "        \"alpha\": alpha,\n",
    "        \"simulations\": sims_done,\n",
    "        \"note\": note\n",
    "    }\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# IMPORTANCE SAMPLING (STREAMING) — ADD EARLY STOP + FASTER MATH\n",
    "###############################################################################\n",
    "def mc_importance_sampling_streaming(\n",
    "    payoff_nd, payoff_d, pd_1y, corr,\n",
    "    alpha, seed, pd_floor, tilt,\n",
    "    min_sims, max_sims, chunk,\n",
    "    target_rel_se, print_every_chunks=10\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    payoff_nd = np.asarray(payoff_nd, dtype=np.float32)\n",
    "    payoff_d  = np.asarray(payoff_d,  dtype=np.float32)\n",
    "    pd_1y     = np.asarray(pd_1y,     dtype=np.float32)\n",
    "    corr      = np.asarray(corr,      dtype=np.float32)\n",
    "\n",
    "    n = len(payoff_nd)\n",
    "    base = float(payoff_nd.sum())\n",
    "\n",
    "    L = np.linalg.cholesky(corr).astype(np.float32)\n",
    "    zcrit = norm.ppf(np.clip(pd_1y, pd_floor, 1 - 1e-12)).astype(np.float32)\n",
    "\n",
    "    # shift (tilt)\n",
    "    mu = (tilt * zcrit).astype(np.float32)\n",
    "    mu2 = float(np.dot(mu, mu))  # scalar\n",
    "\n",
    "    # Streaming accumulators under true measure:\n",
    "    sims_done = 0\n",
    "    w_sum = 0.0\n",
    "    wL_sum = 0.0\n",
    "    wL2_sum = 0.0      # for SE of weighted estimator\n",
    "    w_pos_sum = 0.0\n",
    "    defaults_seen_tilted = 0\n",
    "\n",
    "    chunks_done = 0\n",
    "    while sims_done < max_sims:\n",
    "        m = min(chunk, max_sims - sims_done)\n",
    "\n",
    "        z  = rng.standard_normal(size=(m, n)).astype(np.float32)\n",
    "        zc = z @ L.T\n",
    "\n",
    "        zc_tilt = zc + mu\n",
    "        default = (zc_tilt < zcrit)\n",
    "        defaults_seen_tilted += int(default.any(axis=1).sum())\n",
    "\n",
    "        payoff = np.where(default, payoff_d, payoff_nd)\n",
    "        port_payoff = payoff.sum(axis=1, dtype=np.float32)\n",
    "        loss = (base - port_payoff).astype(np.float32)\n",
    "\n",
    "        # weights (compute in float64 for stability)\n",
    "        # dot each row with mu:\n",
    "        dot = (zc.astype(np.float64) @ mu.astype(np.float64))\n",
    "        logw = -(dot) - 0.5 * mu2\n",
    "        w = np.exp(logw)  # float64\n",
    "\n",
    "        loss64 = loss.astype(np.float64)\n",
    "\n",
    "        # update sums\n",
    "        sims_done += m\n",
    "        chunks_done += 1\n",
    "\n",
    "        w_sum   += float(w.sum())\n",
    "        wL      = w * loss64\n",
    "        wL_sum  += float(wL.sum())\n",
    "        wL2_sum += float((wL * loss64).sum())  # E[w*L^2] numerator-ish for SE approx\n",
    "        w_pos_sum += float(w[loss > 0].sum())\n",
    "\n",
    "        # early stop based on approximate relative SE of EL = (sum wL)/(sum w)\n",
    "        if sims_done >= min_sims and w_sum > 0:\n",
    "            EL = wL_sum / w_sum\n",
    "\n",
    "            # crude but useful SE approximation:\n",
    "            # Var_hat ≈ (E[w*L^2]/E[w]) - EL^2 ; SE ≈ sqrt(Var_hat / ESS)\n",
    "            # ESS ≈ (sum w)^2 / sum(w^2)\n",
    "            w2_sum = float((w * w).sum())\n",
    "            ESS = (w_sum * w_sum) / (w2_sum + 1e-300)\n",
    "\n",
    "            EwL2_over_Ew = (wL2_sum / w_sum) if w_sum > 0 else 0.0\n",
    "            var_hat = max(0.0, EwL2_over_Ew - EL * EL)\n",
    "            se = (var_hat / max(1.0, ESS)) ** 0.5\n",
    "            rel_se = se / (abs(EL) + 1e-30)\n",
    "\n",
    "            if rel_se <= target_rel_se:\n",
    "                break\n",
    "\n",
    "        if print_every_chunks and (chunks_done % print_every_chunks == 0) and w_sum > 0:\n",
    "            EL = wL_sum / w_sum\n",
    "            ppos = w_pos_sum / w_sum\n",
    "            print(f\"[IS] sims={sims_done:,}  EL≈{EL:.6g}  P(L>0)≈{ppos:.6g}\")\n",
    "\n",
    "    EL = wL_sum / w_sum if w_sum > 0 else 0.0\n",
    "    p_pos = w_pos_sum / w_sum if w_sum > 0 else 0.0\n",
    "    p_tail = 1.0 - alpha\n",
    "\n",
    "    if p_pos < p_tail:\n",
    "        VaR = 0.0\n",
    "        ES = EL / p_tail if p_tail > 0 else 0.0\n",
    "        note = \"Rare-event regime: VaR=0, ES=EL/(1-alpha).\"\n",
    "    else:\n",
    "        VaR = None\n",
    "        ES = None\n",
    "        note = \"P(L>0) >= 1-alpha; need weighted-quantile method if you truly need VaR/ES.\"\n",
    "\n",
    "    return {\n",
    "        \"method\": \"importance_sampling_streaming\",\n",
    "        \"VaR\": VaR,\n",
    "        \"ES\": ES,\n",
    "        \"Expected_Loss\": EL,\n",
    "        \"P(Loss>0)\": p_pos,\n",
    "        \"alpha\": alpha,\n",
    "        \"simulations\": sims_done,\n",
    "        \"tilt_strength\": tilt,\n",
    "        \"tilted_default_paths_seen\": defaults_seen_tilted,\n",
    "        \"note\": note\n",
    "    }\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# MAIN\n",
    "###############################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    names, payoff_nd, payoff_d, pd_1y = load_bond_data(EXCEL_PATH)\n",
    "    corr, cols = load_corr(EXCEL_PATH)\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADED DATA FROM EXCEL\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nIssuers: {names}\")\n",
    "    print(f\"\\nPayoff (No Default): {payoff_nd}\")\n",
    "    print(f\"Payoff (Default):    {payoff_d}\")\n",
    "    \n",
    "    print(f\"\\n[CRITICAL] PDs loaded from Excel:\")\n",
    "    for i, (name, pd) in enumerate(zip(names, pd_1y)):\n",
    "        print(f\"  {name}: {pd:.10e}\")\n",
    "    print(f\"Sum of PDs: {float(np.sum(pd_1y)):.10e}\")\n",
    "    \n",
    "    print(f\"\\nCorrelation columns found: {cols}\")\n",
    "    print(f\"Correlation matrix shape: {corr.shape}\")\n",
    "    print(f\"Correlation matrix:\\n{corr}\")\n",
    "    \n",
    "    brute = mc_bruteforce_streaming(\n",
    "        payoff_nd, payoff_d, pd_1y, corr,\n",
    "        alpha=ALPHA, seed=SEED, pd_floor=PD_FLOOR,\n",
    "        min_sims=MIN_SIMS_BRUTE, max_sims=MAX_SIMS_BRUTE, chunk=CHUNK,\n",
    "        target_rel_se=TARGET_REL_SE_BRUTE, print_every_chunks=PRINT_EVERY_CHUNKS\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- BRUTE FORCE (STREAMING) ---\")\n",
    "    for k, v in brute.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    is_stats = mc_importance_sampling_streaming(\n",
    "        payoff_nd, payoff_d, pd_1y, corr,\n",
    "        alpha=ALPHA, seed=SEED + 1, pd_floor=PD_FLOOR, tilt=TILT,\n",
    "        min_sims=MIN_SIMS_IS, max_sims=MAX_SIMS_IS, chunk=CHUNK,\n",
    "        target_rel_se=TARGET_REL_SE_IS, print_every_chunks=PRINT_EVERY_CHUNKS\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- IMPORTANCE SAMPLING (STREAMING) ---\")\n",
    "    for k, v in is_stats.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1735d480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "GENERATING DIAGNOSTIC VISUALIZATIONS\n",
      "======================================================================\n",
      "✓ Convergence: Fig_Convergence.png\n",
      "✓ Comparison: Fig_SimulationComparison.png\n",
      "✓ Analysis: Fig_DefaultAnalysis.png\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('agg')  # Non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "###############################################################################\n",
    "# CONFIG\n",
    "###############################################################################\n",
    "EXCEL_PATH = r\"C:\\Users\\Tom\\Git Repos\\tomd6464\\Risk_1\\MCS_Bond_Sim\\MCS_Bond.xlsx\"\n",
    "SEED = 1\n",
    "PD_FLOOR = 1e-50\n",
    "\n",
    "###############################################################################\n",
    "# LOAD DATA FROM EXCEL\n",
    "###############################################################################\n",
    "def load_bond_data(excel_path):\n",
    "    raw = pd.read_excel(excel_path, sheet_name=\"Bond_Data\", header=None)\n",
    "    issuer_row = raw.index[raw[1].astype(str).str.strip() == \"Issuer\"][0]\n",
    "    names = raw.loc[issuer_row, 2:4].tolist()\n",
    "\n",
    "    def get_row(label):\n",
    "        r = raw.index[raw[1].astype(str).str.strip() == label][0]\n",
    "        return raw.loc[r, 2:4].astype(float).to_numpy()\n",
    "\n",
    "    payoff_nd = get_row(\"Payoff N.d.\")\n",
    "    payoff_d  = get_row(\"Payoff (D)\")\n",
    "    kmv_row = raw.index[raw[1].astype(str).str.strip() == \"KMV Output\"][0]\n",
    "    pd_1y = raw.loc[kmv_row + 1, 2:4].astype(float).to_numpy()\n",
    "\n",
    "    return names, payoff_nd, payoff_d, pd_1y\n",
    "\n",
    "\n",
    "def load_corr(excel_path):\n",
    "    df = pd.read_excel(excel_path, sheet_name=\"Bond_Stock_data\", header=1)\n",
    "    norm_cols = [c for c in df.columns if str(c).endswith(\"Return.1\")]\n",
    "\n",
    "    if len(norm_cols) < 3:\n",
    "        raise ValueError(f\"Couldn't find 3 normalised return columns. Found: {norm_cols}\")\n",
    "\n",
    "    corr = df[norm_cols].dropna().corr().to_numpy()\n",
    "    corr = (corr + corr.T) / 2.0\n",
    "    np.fill_diagonal(corr, 1.0)\n",
    "    return corr, norm_cols\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# VISUALIZATION FUNCTIONS\n",
    "###############################################################################\n",
    "\n",
    "def plot_convergence_streaming(\n",
    "    payoff_nd, payoff_d, pd_1y, corr,\n",
    "    seed, pd_floor,\n",
    "    max_sims=10_000_000,\n",
    "    chunk=500_000,\n",
    "    out_png=\"Fig_Convergence.png\"\n",
    "):\n",
    "    \"\"\"Track EL and P(Loss>0) convergence across simulation batches (downsampled for plotting).\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    payoff_nd = np.asarray(payoff_nd, dtype=np.float32)\n",
    "    payoff_d  = np.asarray(payoff_d,  dtype=np.float32)\n",
    "    pd_1y     = np.asarray(pd_1y,     dtype=np.float32)\n",
    "    corr      = np.asarray(corr,      dtype=np.float32)\n",
    "\n",
    "    n = len(payoff_nd)\n",
    "    base = float(payoff_nd.sum())\n",
    "\n",
    "    L = np.linalg.cholesky(corr).astype(np.float32)\n",
    "    zcrit = norm.ppf(np.clip(pd_1y, pd_floor, 1 - 1e-12)).astype(np.float32)\n",
    "\n",
    "    sims_log = []\n",
    "    el_log = []\n",
    "    ppos_log = []\n",
    "\n",
    "    sims_done = 0\n",
    "    sum_L = 0.0\n",
    "    count_pos = 0\n",
    "    last_logged = 0\n",
    "\n",
    "    while sims_done < max_sims:\n",
    "        m = min(chunk, max_sims - sims_done)\n",
    "\n",
    "        z  = rng.standard_normal(size=(m, n)).astype(np.float32)\n",
    "        zc = z @ L.T\n",
    "\n",
    "        default = (zc < zcrit)\n",
    "        payoff = np.where(default, payoff_d, payoff_nd)\n",
    "        port_payoff = payoff.sum(axis=1, dtype=np.float32)\n",
    "        loss = (base - port_payoff).astype(np.float32)\n",
    "\n",
    "        sims_done += m\n",
    "        sum_L  += float(loss.sum())\n",
    "        count_pos += int((loss > 0).sum())\n",
    "\n",
    "        if sims_done - last_logged >= chunk * 5 or sims_done >= max_sims:\n",
    "            sims_log.append(sims_done)\n",
    "            el_log.append(sum_L / sims_done)\n",
    "            ppos_log.append(count_pos / sims_done)\n",
    "            last_logged = sims_done\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), dpi=100)\n",
    "\n",
    "    ax1.plot(np.array(sims_log) / 1e6, el_log, linewidth=2, marker='o', markersize=4)\n",
    "    ax1.set_xlabel(\"Simulations (millions)\")\n",
    "    ax1.set_ylabel(\"Expected Loss\")\n",
    "    ax1.set_title(\"Convergence of Expected Loss\")\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    ax2.plot(np.array(sims_log) / 1e6, ppos_log, linewidth=2, marker='o', markersize=4, color='orange')\n",
    "    ax2.set_xlabel(\"Simulations (millions)\")\n",
    "    ax2.set_ylabel(\"P(Loss > 0)\")\n",
    "    ax2.set_title(\"Convergence of Default Probability\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=100, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    return {\"out_png\": out_png, \"final_el\": el_log[-1], \"final_ppos\": ppos_log[-1], \"points_plotted\": len(sims_log)}\n",
    "\n",
    "\n",
    "def plot_simulation_comparison(brute_stats, is_stats, out_png=\"Fig_SimulationComparison.png\"):\n",
    "    \"\"\"Bar chart comparing brute force vs importance sampling effort.\"\"\"\n",
    "    methods = [\"Brute Force\", \"Importance Sampling\"]\n",
    "    sims = [brute_stats[\"simulations\"], is_stats[\"simulations\"]]\n",
    "    colors = [\"#1f77b4\", \"#ff7f0e\"]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=100)\n",
    "    bars = ax.bar(methods, np.array(sims) / 1e6, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "    for bar, s in zip(bars, sims):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height, f'{s/1e6:.1f}M', \n",
    "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "    ax.set_ylabel(\"Number of Simulations (millions)\", fontsize=12)\n",
    "    ax.set_title(\"Simulation Effort: Brute Force vs Importance Sampling\", fontsize=13)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=100, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    return {\"out_png\": out_png}\n",
    "\n",
    "\n",
    "def plot_default_analysis(pd_1y, corr, out_png=\"Fig_DefaultAnalysis.png\"):\n",
    "    \"\"\"Visualize why defaults are rare.\"\"\"\n",
    "    n_issuers = len(pd_1y)\n",
    "    \n",
    "    fig = plt.figure(figsize=(11, 8), dpi=100)\n",
    "    gs = fig.add_gridspec(2, 2, hspace=0.35, wspace=0.35)\n",
    "\n",
    "    # Plot 1: Individual PDs\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    issuer_labels = [f\"Issuer {i+1}\" for i in range(n_issuers)]\n",
    "    ax1.bar(issuer_labels, pd_1y * 100, color='#d62728', alpha=0.7, edgecolor='black')\n",
    "    ax1.set_ylabel(\"PD (%)\", fontsize=10)\n",
    "    ax1.set_title(\"Default Probabilities\", fontsize=11, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Plot 2: Correlation matrix heatmap\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    if n_issuers > 1:\n",
    "        im = ax2.imshow(corr, cmap='coolwarm', vmin=0, vmax=1, aspect='auto')\n",
    "        ax2.set_xticks(range(len(issuer_labels)))\n",
    "        ax2.set_yticks(range(len(issuer_labels)))\n",
    "        ax2.set_xticklabels(issuer_labels, fontsize=9)\n",
    "        ax2.set_yticklabels(issuer_labels, fontsize=9)\n",
    "        ax2.set_title(\"Correlation Matrix\", fontsize=11, fontweight='bold')\n",
    "        plt.colorbar(im, ax=ax2, label='ρ')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'N/A', ha='center', va='center', fontsize=14)\n",
    "        ax2.set_title(\"Correlation (N/A)\", fontsize=11, fontweight='bold')\n",
    "        ax2.axis('off')\n",
    "\n",
    "    # Plot 3: Joint default probability\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    joint_ind = np.prod(pd_1y)\n",
    "    \n",
    "    if n_issuers > 1:\n",
    "        mean_corr = np.mean(np.triu(corr, 1))\n",
    "        scenarios = ['Independent', f'Correlated']\n",
    "        joint_probs = [joint_ind * 100, joint_ind * (1 + mean_corr) * 100]\n",
    "    else:\n",
    "        scenarios = ['Default Prob']\n",
    "        joint_probs = [joint_ind * 100]\n",
    "\n",
    "    ax3.bar(scenarios, joint_probs, color=['#2ca02c', '#ff7f0e'][:len(scenarios)], alpha=0.7, edgecolor='black')\n",
    "    ax3.set_ylabel(\"Probability (%)\", fontsize=10)\n",
    "    ax3.set_title(\"Joint Default Analysis\", fontsize=11, fontweight='bold')\n",
    "    ax3.set_yscale('log')\n",
    "\n",
    "    # Plot 4: Summary text\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    summary_text = (\n",
    "        f\"Summary\\n\"\n",
    "        f\"Max PD: {np.max(pd_1y)*100:.4f}%\\n\"\n",
    "        f\"Min PD: {np.min(pd_1y)*100:.4f}%\\n\\n\"\n",
    "        f\"Very low PDs mean\\n\"\n",
    "        f\"defaults are rare.\\n\"\n",
    "        f\"MC needs many sims.\"\n",
    "    )\n",
    "    ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes,\n",
    "            fontsize=9, verticalalignment='top', fontfamily='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "    plt.savefig(out_png, dpi=100, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    return {\"out_png\": out_png}\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# RUN ALL VISUALIZATIONS\n",
    "###############################################################################\n",
    "names, payoff_nd, payoff_d, pd_1y = load_bond_data(EXCEL_PATH)\n",
    "corr, cols = load_corr(EXCEL_PATH)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING DIAGNOSTIC VISUALIZATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    max_sims_to_plot = brute['simulations']\n",
    "except NameError:\n",
    "    print(\"\\n⚠ WARNING: Run cell 1 first to generate simulation results.\")\n",
    "    max_sims_to_plot = 10_000_000\n",
    "\n",
    "conv = plot_convergence_streaming(payoff_nd, payoff_d, pd_1y, corr, SEED, PD_FLOOR, max_sims_to_plot, 500_000, \"Fig_Convergence.png\")\n",
    "print(f\"✓ Convergence: {conv['out_png']}\")\n",
    "\n",
    "try:\n",
    "    comp = plot_simulation_comparison(brute, is_stats, \"Fig_SimulationComparison.png\")\n",
    "    print(f\"✓ Comparison: {comp['out_png']}\")\n",
    "except NameError:\n",
    "    print(\"⚠ Skipping comparison. Run cell 1 first.\")\n",
    "\n",
    "deflt = plot_default_analysis(pd_1y, corr, \"Fig_DefaultAnalysis.png\")\n",
    "print(f\"✓ Analysis: {deflt['out_png']}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32970e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "P(LOSS > 0) CONVERGENCE ANALYSIS\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tom\\AppData\\Local\\Temp\\ipykernel_19680\\905868304.py:151: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Linear Scale Chart: Fig_PLoss_Convergence.png\n",
      "✓ Log-Log Scale Chart: Fig_PLoss_Convergence_loglog.png\n",
      "  Total Simulations: 100,000,000\n",
      "  Final P(Loss > 0): 0.00000000%\n",
      "  Final Std Error: 0.00000000%\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "###############################################################################\n",
    "# CONFIG\n",
    "###############################################################################\n",
    "EXCEL_PATH = r\"C:\\Users\\Tom\\Git Repos\\tomd6464\\Risk_1\\MCS_Bond_Sim\\MCS_Bond.xlsx\"\n",
    "SEED = 1\n",
    "PD_FLOOR = 1e-50\n",
    "\n",
    "###############################################################################\n",
    "# LOAD DATA FROM EXCEL\n",
    "###############################################################################\n",
    "def load_bond_data(excel_path):\n",
    "    raw = pd.read_excel(excel_path, sheet_name=\"Bond_Data\", header=None)\n",
    "    issuer_row = raw.index[raw[1].astype(str).str.strip() == \"Issuer\"][0]\n",
    "    names = raw.loc[issuer_row, 2:4].tolist()\n",
    "\n",
    "    def get_row(label):\n",
    "        r = raw.index[raw[1].astype(str).str.strip() == label][0]\n",
    "        return raw.loc[r, 2:4].astype(float).to_numpy()\n",
    "\n",
    "    payoff_nd = get_row(\"Payoff N.d.\")\n",
    "    payoff_d  = get_row(\"Payoff (D)\")\n",
    "    kmv_row = raw.index[raw[1].astype(str).str.strip() == \"KMV Output\"][0]\n",
    "    pd_1y = raw.loc[kmv_row + 1, 2:4].astype(float).to_numpy()\n",
    "\n",
    "    return names, payoff_nd, payoff_d, pd_1y\n",
    "\n",
    "\n",
    "def load_corr(excel_path):\n",
    "    df = pd.read_excel(excel_path, sheet_name=\"Bond_Stock_data\", header=1)\n",
    "    norm_cols = [c for c in df.columns if str(c).endswith(\"Return.1\")]\n",
    "\n",
    "    if len(norm_cols) < 3:\n",
    "        raise ValueError(f\"Couldn't find 3 normalised return columns. Found: {norm_cols}\")\n",
    "\n",
    "    corr = df[norm_cols].dropna().corr().to_numpy()\n",
    "    corr = (corr + corr.T) / 2.0\n",
    "    np.fill_diagonal(corr, 1.0)\n",
    "    return corr, norm_cols\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# PROBABILITY OF LOSS CONVERGENCE TRACKING\n",
    "###############################################################################\n",
    "def plot_plos_convergence_detailed(\n",
    "    payoff_nd, payoff_d, pd_1y, corr,\n",
    "    seed, pd_floor,\n",
    "    max_sims=100_000_000,\n",
    "    chunk=500_000,\n",
    "    out_png=\"Fig_PLoss_Convergence.png\"\n",
    "):\n",
    "    \"\"\"Track P(Loss>0) with detailed milestone markers and confidence bands.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    payoff_nd = np.asarray(payoff_nd, dtype=np.float32)\n",
    "    payoff_d  = np.asarray(payoff_d,  dtype=np.float32)\n",
    "    pd_1y     = np.asarray(pd_1y,     dtype=np.float32)\n",
    "    corr      = np.asarray(corr,      dtype=np.float32)\n",
    "\n",
    "    n = len(payoff_nd)\n",
    "    base = float(payoff_nd.sum())\n",
    "\n",
    "    L = np.linalg.cholesky(corr).astype(np.float32)\n",
    "    zcrit = norm.ppf(np.clip(pd_1y, pd_floor, 1 - 1e-12)).astype(np.float32)\n",
    "\n",
    "    sims_log = []\n",
    "    plos_log = []\n",
    "    plos_se_log = []\n",
    "\n",
    "    sims_done = 0\n",
    "    count_pos = 0\n",
    "\n",
    "    while sims_done < max_sims:\n",
    "        m = min(chunk, max_sims - sims_done)\n",
    "\n",
    "        z  = rng.standard_normal(size=(m, n)).astype(np.float32)\n",
    "        zc = z @ L.T\n",
    "\n",
    "        default = (zc < zcrit)\n",
    "        payoff = np.where(default, payoff_d, payoff_nd)\n",
    "        port_payoff = payoff.sum(axis=1, dtype=np.float32)\n",
    "        loss = (base - port_payoff).astype(np.float32)\n",
    "\n",
    "        sims_done += m\n",
    "        count_pos += int((loss > 0).sum())\n",
    "\n",
    "        p_los = count_pos / sims_done\n",
    "        se_plos = np.sqrt(p_los * (1 - p_los) / sims_done)\n",
    "        \n",
    "        sims_log.append(sims_done)\n",
    "        plos_log.append(p_los)\n",
    "        plos_se_log.append(se_plos)\n",
    "\n",
    "    sims_array = np.array(sims_log) / 1e6\n",
    "    plos_array = np.array(plos_log)\n",
    "    se_array = np.array(plos_se_log)\n",
    "\n",
    "    upper_band = plos_array + 1.96 * se_array\n",
    "    lower_band = np.maximum(plos_array - 1.96 * se_array, 0)\n",
    "    final_plos = plos_array[-1]\n",
    "\n",
    "    # Figure 1: Linear scale with zoomed y-axis\n",
    "    fig1, ax1 = plt.subplots(figsize=(12, 7), dpi=100)\n",
    "    ax1.plot(sims_array, plos_array, linewidth=2.5, color='#1f77b4', label='P(Loss > 0)', zorder=3)\n",
    "    ax1.fill_between(sims_array, lower_band, upper_band, alpha=0.2, color='#1f77b4', label='95% Confidence Band', zorder=1)\n",
    "    \n",
    "    ax1.axhline(y=final_plos, color='red', linestyle='--', linewidth=1.5, alpha=0.7, \n",
    "                label=f'Final: {final_plos:.6e}')\n",
    "    \n",
    "    # Set y-axis limits to the observed range with 10% padding\n",
    "    y_min = min(lower_band) * 0.9\n",
    "    y_max = max(upper_band) * 1.1\n",
    "    ax1.set_ylim([y_min, y_max])\n",
    "    \n",
    "    ax1.set_xlabel(\"Simulations (millions)\", fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel(\"P(Loss > 0)\", fontsize=12, fontweight='bold')\n",
    "    ax1.set_title(\"P(Loss > 0) Convergence (Linear Scale - Zoomed to Data)\", fontsize=13, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax1.legend(fontsize=11, loc='best')\n",
    "    ax1.ticklabel_format(style='sci', axis='y', scilimits=(0, 0))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=100, bbox_inches='tight')\n",
    "    plt.close(fig1)\n",
    "\n",
    "    # Figure 2: Log-log scale\n",
    "    fig2, ax2 = plt.subplots(figsize=(12, 7), dpi=100)\n",
    "    \n",
    "    mask = plos_array > 0\n",
    "    ax2.loglog(sims_array[mask], plos_array[mask], linewidth=2.5, color='#1f77b4', \n",
    "               marker='o', markersize=3, label='P(Loss > 0)', zorder=3)\n",
    "    \n",
    "    ax2.fill_between(sims_array[mask], \n",
    "                     np.maximum(lower_band[mask], 1e-35),\n",
    "                     upper_band[mask], \n",
    "                     alpha=0.2, color='#1f77b4', label='95% Confidence Band', zorder=1)\n",
    "    \n",
    "    ax2.axhline(y=final_plos, color='red', linestyle='--', linewidth=1.5, alpha=0.7, \n",
    "                label=f'Final: {final_plos:.6e}')\n",
    "    \n",
    "    ax2.set_xlabel(\"Simulations (millions, log scale)\", fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel(\"P(Loss > 0) (log scale)\", fontsize=12, fontweight='bold')\n",
    "    ax2.set_title(\"P(Loss > 0) Convergence (Log-Log Scale)\", fontsize=13, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, linestyle='--', which='both')\n",
    "    ax2.legend(fontsize=11, loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png.replace('.png', '_loglog.png'), dpi=100, bbox_inches='tight')\n",
    "    plt.close(fig2)\n",
    "\n",
    "    return {\n",
    "        \"out_png_linear\": out_png,\n",
    "        \"out_png_loglog\": out_png.replace('.png', '_loglog.png'),\n",
    "        \"final_plos\": final_plos,\n",
    "        \"final_se\": se_array[-1],\n",
    "        \"total_sims\": sims_done,\n",
    "        \"y_min\": y_min,\n",
    "        \"y_max\": y_max\n",
    "    }\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# RUN CONVERGENCE ANALYSIS\n",
    "###############################################################################\n",
    "names, payoff_nd, payoff_d, pd_1y = load_bond_data(EXCEL_PATH)\n",
    "corr, cols = load_corr(EXCEL_PATH)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"P(LOSS > 0) CONVERGENCE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "conv_plos = plot_plos_convergence_detailed(\n",
    "    payoff_nd, payoff_d, pd_1y, corr,\n",
    "    seed=SEED, pd_floor=PD_FLOOR,\n",
    "    max_sims=100_000_000,\n",
    "    chunk=500_000,\n",
    "    out_png=\"Fig_PLoss_Convergence.png\"\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Linear Scale Chart: {conv_plos['out_png_linear']}\")\n",
    "print(f\"✓ Log-Log Scale Chart: {conv_plos['out_png_loglog']}\")\n",
    "print(f\"  Total Simulations: {conv_plos['total_sims']:,}\")\n",
    "print(f\"  Final P(Loss > 0): {conv_plos['final_plos']:.6e}\")\n",
    "print(f\"  Y-axis range: [{conv_plos['y_min']:.6e}, {conv_plos['y_max']:.6e}]\")\n",
    "print(f\"  Final Std Error: {conv_plos['final_se']:.6e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
